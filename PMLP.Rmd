---
title: "Practical Machine Learning  Write up"
output: html_document
---

# Getting Data

Training data was obtained from https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv

Testing data was obtained from https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv

Libraries included for analysis
```{r,results='hide'}
library(ggplot2)
library(caret)
library(randomForest)
library(gbm)
library(doParallel)
library(dplyr)
library(e1071)
trainset <- read.csv("pml-training.csv", head=TRUE, sep=",", na.strings=c("NA","#DIV/0!","")) 
testset <- read.csv("pml-testing.csv", head=TRUE, sep=",", na.strings=c("NA","#DIV/0!",""))  

```

# Data Cleanup

Data obtained in the testing and traning set need to be cleaned up, columns contaning a majority of NA values need to be removed, columns with low variance also need to be removed. In the end we should be left with only those coulums wich influence the prediction.

```{r}

threshold <- sapply(trainset, function(df) {sum(is.na(df)==TRUE)/length(df)})
thresholdtest <- sapply(testset, function(df) {sum(is.na(df)==TRUE)/length(df)})

traincolidx <-names(which(threshold<0.95))
trainset<-trainset[,traincolidx]
testcolidx  <-names(which(thresholdtest<0.95))
testset<-testset[,testcolidx]

nov1 <- nearZeroVar(trainset,saveMetrics=TRUE)
nov2 <- nearZeroVar(testset,saveMetrics=TRUE)
goodTrainData <- trainset[,which(nov1$nzv==FALSE)]
goodTestData <- testset[,which(nov2$nzv==FALSE)]

RmInx1 <- grepl("X|timestamp|user_name", names(goodTrainData))
goodTrainData <- goodTrainData[, which(RmInx1 ==FALSE)]

RmInx2 <- grepl("X|timestamp|user_name|problem_id", names(goodTestData))
goodTestData <- goodTestData[, which(RmInx2 ==FALSE)]


set.seed(35161)
indexTrain <- createDataPartition (goodTrainData$classe, p=0.75, list=FALSE)
testing <-goodTrainData [- indexTrain,]
inTrain <- createDataPartition(testing$classe, p = 0.75)[[1]]
crossv_test <- testing[ -inTrain,]
training <- goodTrainData [indexTrain ,]
testing<-testing[inTrain,]

```

# Training Random Forest 

We use parallel processing to increase the training speed
```{r}
 cl <- makeCluster(detectCores())
 registerDoParallel(cl)
 mod1 <- train(classe ~ ., data=training, method="rf")
 pred1 <- predict(mod1, testing)
 stopCluster(cl)
 plot(mod1$finalModel)
```

## Displaying the confusion matrix

```{r}
 confusionMatrix(pred1, testing$classe)
```

The confusion matrix gives and accuracy of 99.69%
 
## Importance of predictors
 
 ```{r}
 print(plot(varImp(mod1)))
 ```
## Out of sample error 
 ```{r}
pred1 <- predict(mod1,crossv_test)
accuracy <- sum(pred1 == crossv_test$classe) / length(pred1)
accuracy
 ```
The out of sample Error achieved is  99.67 % with the validation set.
 
## Prediction of new values
 
The final step is to use the model and predict values from our test case
 ```{r}
 final<- predict(mod1,goodTestData)
 final
 ```
